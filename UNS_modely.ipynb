{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "X = pd.read_csv('X_updated.csv')\n",
    "y = pd.read_csv('y_updated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.drop(columns='Unnamed: 0')\n",
    "X = X.drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['ProductItem_Combined'] = y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode= X.Business_service.mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['Business_service'] = X.Business_service.fillna(mode[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by the class column\n",
    "groupedModel_number = X.groupby('Business_service')\n",
    "\n",
    "# Find the size of each group\n",
    "group_sizesModel_number = groupedModel_number.size()\n",
    "\n",
    "# Find the class names of the smallest groups\n",
    "to_dropModel_number = group_sizesModel_number[group_sizesModel_number  < 2].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[~X['Business_service'].isin(to_dropModel_number)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.DataFrame(X['ProductItem_Combined'])\n",
    "X= X.drop(columns='ProductItem_Combined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test =  train_test_split( X, y, test_size=0.33, random_state=15000, stratify= X.Business_service)\n",
    "tempSimTrain= pd.DataFrame()\n",
    "tempSimTest = pd.DataFrame()\n",
    "tempSimTrain['avg_sim'] = X_train['name_similarity']\n",
    "tempSimTest['avg_sim'] = X_test['name_similarity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = ['Company','Model_ID','Model_number','Business_service']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[pred].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[pred].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder as SklearnOneHotEncoder\n",
    "\n",
    "class OneHotEncoder(SklearnOneHotEncoder):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(OneHotEncoder, self).__init__(**kwargs)\n",
    "        self.fit_flag = False\n",
    "\n",
    "    def fit(self, X, **kwargs):\n",
    "        out = super().fit(X)\n",
    "        self.fit_flag = True\n",
    "        return out\n",
    "\n",
    "    def transform(self, X, **kwargs):\n",
    "        sparse_matrix = super(OneHotEncoder, self).transform(X)\n",
    "        new_columns = self.get_new_columns(X=X)\n",
    "        d_out = pd.DataFrame(sparse_matrix.toarray(), columns=new_columns, index=X.index)\n",
    "        return d_out\n",
    "\n",
    "    def fit_transform(self, X, **kwargs):\n",
    "        self.fit(X)\n",
    "        return self.transform(X)\n",
    "\n",
    "    def get_new_columns(self, X):\n",
    "        new_columns = []\n",
    "        for i, column in enumerate(X.columns):\n",
    "            j = 0\n",
    "            while j < len(self.categories_[i]):\n",
    "                new_columns.append(f'{column}_<{self.categories_[i][j]}>')\n",
    "                j += 1\n",
    "        return new_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.iloc[:, [0,1,2,3,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "encoderX = OneHotEncoder()\n",
    "encoderY =  OneHotEncoder()\n",
    "\n",
    "X_train = encoderX.fit_transform(X_train.iloc[:, [0,1,2,3,4]])\n",
    "X_test = encoderX.fit_transform(X_test.iloc[:, [0,1,2,3,4]])\n",
    "y_train= encoderY.fit_transform(y_train)\n",
    "y_test = encoderY.fit_transform(y_test)\n",
    "\n",
    "X_train['name_similarity'] = tempSimTrain['avg_sim']\n",
    "X_test['name_similarity']  =  tempSimTest['avg_sim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Imports\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "import keras\n",
    "# Create the model\n",
    "def build_MLP():\n",
    "    model_ann = Sequential()\n",
    "    model_ann.add(Dense(480, activation='relu', input_dim=818))\n",
    "    model_ann.add(Dropout(0.5))\n",
    "    model_ann.add(Dense(240, activation='relu'))\n",
    "    model_ann.add(Dropout(0.5))\n",
    "    model_ann.add(Dense(17, activation='softmax'))\n",
    "    model_ann.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(lr=0.001, decay=1e-6, clipvalue=0.5), metrics=['Recall','Precision', 'accuracy'])\n",
    "    return model_ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ann = build_MLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historyANN = model_ann.fit(X_train, y_train, epochs=10, batch_size= 100)\n",
    "#validation_data=(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ann.evaluate(X_test, y_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "tensorboard_callback = TensorBoard(log_dir='./logs', histogram_freq=1)\n",
    "\n",
    "model_ann.fit(X_train, y_train, epochs=10, callbacks=[tensorboard_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ann.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "# Generate predictions on the test set\n",
    "y_pred = model_ann.predict(X_test)\n",
    "\n",
    "pred_classes = np.argmax(y_pred, axis=1)\n",
    "true_classes = np.argmax(np.array(y_test), axis=1)\n",
    "\n",
    "\n",
    "conf_matrix = confusion_matrix(true_classes, pred_classes, labels=range(17))\n",
    "\n",
    "plt.figure(figsize =(10, 5)) \n",
    "sns.heatmap(conf_matrix, annot = True, fmt =\"d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classess = []\n",
    "for i in range(0,17):\n",
    "    classess.append(f\"Class {i}\")\n",
    "    \n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "precision, recall, f1_score, support = precision_recall_fscore_support(true_classes, pred_classes)\n",
    "\n",
    "for i, c in enumerate(classess):\n",
    "    print(f\"Class {c} - Precision: {precision[i]:.2f}, Recall: {recall[i]:.2f}, F1-Score: {f1_score[i]:.2f}, Support: {support[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract the training and validation accuracy\n",
    "acc = historyANN.history['accuracy']\n",
    "val_acc = historyANN.history['val_accuracy']\n",
    "val_prec = historyANN.history['val_precision']\n",
    "prec = historyANN.history['precision']\n",
    "val_recall = historyANN.history['val_recall']\n",
    "recall = historyANN.history['recall']\n",
    "\n",
    "# Plot the accuracy\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.title('Accuracy of Best Model')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = pd.read_csv('frame_updated_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by the class column\n",
    "groupedModel_number = frame.groupby('Business_service')\n",
    "\n",
    "# Find the size of each group\n",
    "group_sizesModel_number = groupedModel_number.size()\n",
    "\n",
    "# Find the class names of the smallest groups\n",
    "to_dropModel_number = group_sizesModel_number[group_sizesModel_number  < 2].index\n",
    "frame = frame[~frame['Business_service'].isin(to_dropModel_number)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.Business_service.value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction with ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping_ann = {index: label for index, label in enumerate(encoderY.get_feature_names_out())}\n",
    "integer_labels_ann = np.argmax(y_pred, axis=1)\n",
    "original_labels_test_ann = [label_mapping_ann[x] for x in integer_labels_ann]\n",
    "original_labels_test_ann = pd.DataFrame(original_labels_test_ann)\n",
    "original_labels_test_ann['original_index'] = y_test.index\n",
    "original_labels_test_ann['pred_ANN'] = original_labels_test_ann[0]\n",
    "original_labels_test_ann = original_labels_test_ann.drop(columns=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction on train set \n",
    "#label mapping for training predictions\n",
    "y_pred_train = model_ann.predict(X_train)\n",
    "label_mapping_train = {index: label for index, label in enumerate(encoderY.get_feature_names_out())}\n",
    "integer_labels_train = np.argmax(y_pred_train, axis=1)\n",
    "original_labels_train = [label_mapping_train[x] for x in integer_labels_train]\n",
    "original_labels_train = pd.DataFrame(original_labels_train)\n",
    "original_labels_train['original_index'] = y_train.index\n",
    "original_labels_train['pred_ANN'] = original_labels_train[0]\n",
    "original_labels_train = original_labels_train.drop(columns=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_set_ann = original_labels_train.merge(original_labels_test_ann, on='original_index', how='outer')\n",
    "joined_set_ann['pred_ANN'] = joined_set_ann['pred_ANN_x'].combine_first(joined_set_ann['pred_ANN_y'])\n",
    "joined_set_ann.drop(['pred_ANN_x', 'pred_ANN_y'], axis=1, inplace=True)\n",
    "joined_set_ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = frame.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.rename(columns={'index' : 'original_index'}, inplace=True)\n",
    "Original_frame = frame.merge(joined_set_ann, on= 'original_index', how='outer')\n",
    "Original_frame.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Original_frame"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, Input\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "\n",
    "import keras\n",
    "# define the model\n",
    "def build_cnn ():\n",
    "    modelCNN = Sequential()\n",
    "    modelCNN.add(Conv1D(64, kernel_size=3, activation='relu', input_shape=(818, 1)))\n",
    "    modelCNN.add(MaxPooling1D(pool_size=2))\n",
    "    modelCNN.add(Dropout(.5))\n",
    "    modelCNN.add(Flatten())\n",
    "    modelCNN.add(Dense(128, activation='relu'))\n",
    "    modelCNN.add(Dropout(.2))\n",
    "    modelCNN.add(Dense(17, activation='softmax'))\n",
    "    # compile the model\n",
    "    modelCNN.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(lr=0.01, decay=1e-6, clipvalue=0.5), metrics=['Recall','Precision', 'accuracy'])\n",
    "    return modelCNN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "import numpy as np\n",
    "\n",
    "#tensorboard_callback_cnn = TensorBoard(log_dir='./logsCNNdipl5', histogram_freq=1)\n",
    "\n",
    "modelCNN = build_cnn()\n",
    "#modelCNN.fit(np.array(X_train), np.array(y_train), epochs=10 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logsCNNdipl/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historyCNN = modelCNN.fit(X_train, y_train, epochs=10, validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelCNN.evaluate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "# Generate predictions on the test set\n",
    "y_pred_cnn = modelCNN.predict(X_test)\n",
    "\n",
    "pred_classes = np.argmax(y_pred_cnn, axis=1)\n",
    "true_classes = np.argmax(np.array(y_test), axis=1)\n",
    "\n",
    "\n",
    "conf_matrix = confusion_matrix(true_classes, pred_classes, labels=range(17))\n",
    "\n",
    "plt.figure(figsize =(10, 5)) \n",
    "sns.heatmap(conf_matrix, annot = True, fmt =\"d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classess = []\n",
    "for i in range(0,17):\n",
    "    classess.append(f\"Class {i}\")\n",
    "    \n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "precision, recall, f1_score, support = precision_recall_fscore_support(true_classes, pred_classes)\n",
    "\n",
    "for i, c in enumerate(classess):\n",
    "    print(f\"Class {c} - Precision: {precision[i]:.2f}, Recall: {recall[i]:.2f}, F1-Score: {f1_score[i]:.2f}, Support: {support[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract the training and validation accuracy\n",
    "acc = historyCNN.history['accuracy']\n",
    "val_acc = historyCNN.history['val_accuracy']\n",
    "val_prec = historyCNN.history['val_precision']\n",
    "prec = historyCNN.history['precision']\n",
    "val_recall = historyCNN.history['val_recall']\n",
    "recall = historyCNN.history['recall']\n",
    "\n",
    "# Plot the accuracy\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.title('Accuracy of CNN Model')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(y_pred_cnn, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping_cnn = {index: label for index, label in enumerate(encoderY.get_feature_names_out())}\n",
    "integer_labels_cnn = np.argmax(y_pred_cnn, axis=1)\n",
    "original_labels_test_cnn = [label_mapping_cnn[x] for x in integer_labels_cnn]\n",
    "original_labels_test_cnn = pd.DataFrame(original_labels_test_cnn)\n",
    "original_labels_test_cnn['original_index'] = y_test.index\n",
    "original_labels_test_cnn['pred_CNN'] = original_labels_test_cnn[0]\n",
    "original_labels_test_cnn = original_labels_test_cnn.drop(columns=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction on train set \n",
    "#label mapping for training predictions\n",
    "y_pred_train_Cnn = modelCNN.predict(X_train)\n",
    "label_mapping_train_cnn = {index: label for index, label in enumerate(encoderY.get_feature_names_out())}\n",
    "integer_labels_train_cnn = np.argmax(y_pred_train, axis=1)\n",
    "original_labels_train_cnn = [label_mapping_train_cnn[x] for x in integer_labels_train_cnn]\n",
    "original_labels_train_cnn = pd.DataFrame(original_labels_train_cnn)\n",
    "original_labels_train_cnn['original_index'] = y_train.index\n",
    "original_labels_train_cnn['pred_CNN'] = original_labels_train_cnn[0]\n",
    "original_labels_train_cnn = original_labels_train_cnn.drop(columns=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {index: label for index, label in enumerate(encoderY.get_feature_names_out())}\n",
    "integer_labels = np.argmax(y_pred_cnn, axis=1)\n",
    "\n",
    "def return_original_labels(label_mapping, integer_labels, y):\n",
    "    original_labels = [label_mapping[x] for x in integer_labels]\n",
    "    original_labels_test = pd.DataFrame(original_labels)\n",
    "    original_labels_test['original_index'] = y.index\n",
    "    original_labels_test['pred_cnn'] = original_labels[0]\n",
    "    original_labels_test = original_labels_test.drop(columns=0)\n",
    "    return original_labels_test\n",
    "\n",
    "original_labels_test= return_original_labels(label_mapping, integer_labels, y_test)\n",
    "original_labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label mapping for training predictions\n",
    "y_pred_train_cnn = modelCNN.predict(X_train)\n",
    "label_mapping_train = {index: label for index, label in enumerate(encoderY.get_feature_names_out())}\n",
    "integer_labels_train = np.argmax(y_pred_train_cnn, axis=1)\n",
    "\n",
    "# original_labels_train = [label_mapping_train[x] for x in integer_labels_train]\n",
    "# original_labels_train = pd.DataFrame(original_labels_train)\n",
    "# original_labels_train['original_index'] = y_train.index\n",
    "# original_labels_train['pred_cnn'] = original_labels_train[0]\n",
    "# original_labels_train = original_labels_train.drop(columns=0)\n",
    "\n",
    "original_labels_train = return_original_labels(label_mapping_train, integer_labels_train, y_train)\n",
    "original_labels_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predictions for CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_set_cnn = original_labels_train_cnn.merge(original_labels_test_cnn, on='original_index', how='outer')\n",
    "joined_set_cnn['pred_CNN'] = joined_set_cnn['pred_CNN_x'].combine_first(joined_set_cnn['pred_CNN_y'])\n",
    "joined_set_cnn.drop(['pred_CNN_x', 'pred_CNN_y'], axis=1, inplace=True)\n",
    "joined_set_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_set_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test  = Original_frame.merge(X.reset_index().rename(columns={'index' :'original_index'}), on= 'original_index' ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Original_frame = Original_frame.merge(joined_set_cnn, on= 'original_index', how='outer')\n",
    "Original_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Original_frame.ProductItem_Combined.unique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune hyperpamateres for ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from kerastuner import RandomSearch\n",
    "\n",
    "\n",
    "# Define the model-building function\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=hp.Int('units_1', min_value=32, max_value=1024, step=32), activation='relu', input_dim=818))\n",
    "    model.add(Dropout(hp.Float('dropout_1', min_value=0.1, max_value=0.5, step=0.1)))\n",
    "    model.add(Dense(units=hp.Int('units_2', min_value=32, max_value=1024, step=32), activation='relu'))\n",
    "    model.add(Dropout(hp.Float('dropout_2', min_value=0.1, max_value=0.5, step=0.1)))\n",
    "    model.add(Dense(17, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',optimizer=keras.optimizers.Adam(lr=hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])), metrics=['Recall', 'Precision', 'accuracy'])\n",
    "    return model\n",
    "\n",
    "# Instantiate the tuner and perform the hyperparameter search\n",
    "tuner = RandomSearch(build_model,objective='val_accuracy', max_trials=10, executions_per_trial=2,directory='my_dir2', project_name='updated_set_ANN1_to_join')\n",
    "\n",
    "tuner.search(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
    "\n",
    "# Print the best hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(f\"Best Hyperparameters: {best_hps}\")\n",
    "\n",
    "# Build the model with the best hyperparameters and train it\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "model.fit(X_train, y_train, epochs=50, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract the training and validation accuracy\n",
    "acc = model.history.history['accuracy']\n",
    "val_acc = model.history.history['val_accuracy']\n",
    "val_prec = model.history.history['val_precision']\n",
    "prec = model.history.history['precision']\n",
    "val_recall = model.history.history['val_recall']\n",
    "recall = model.history.history['recall']\n",
    "\n",
    "# Plot the accuracy\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.title('Accuracy of Best Model')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "# Generate predictions on the test set\n",
    "y_bm_pred_test = model.predict(X_test)\n",
    "\n",
    "pred_classes = np.argmax(y_bm_pred_test, axis=1)\n",
    "true_classes = np.argmax(np.array(y_test), axis=1)\n",
    "\n",
    "\n",
    "conf_matrix = confusion_matrix(true_classes, pred_classes, labels=range(17))\n",
    "\n",
    "plt.figure(figsize =(10, 5)) \n",
    "sns.heatmap(conf_matrix, annot = True, fmt =\"d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_bm_pred_test = model.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict and map results from BM ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping_ann_BM = {index: label for index, label in enumerate(encoderY.get_feature_names_out())}\n",
    "integer_labels_ann_BM = np.argmax(y_bm_pred_test, axis=1)\n",
    "original_labels_test_ann_BM = [label_mapping_ann_BM[x] for x in integer_labels_ann_BM]\n",
    "original_labels_test_ann_BM = pd.DataFrame(original_labels_test_ann_BM)\n",
    "original_labels_test_ann_BM['original_index'] = y_test.index\n",
    "original_labels_test_ann_BM['pred_ANN_BM'] = original_labels_test_ann_BM[0]\n",
    "original_labels_test_ann_BM = original_labels_test_ann_BM.drop(columns=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction on train set \n",
    "#label mapping for training predictions\n",
    "y_pred_train_ann_BM = model.predict(X_train)\n",
    "label_mapping_train_BM = {index: label for index, label in enumerate(encoderY.get_feature_names_out())}\n",
    "integer_labels_train_ann_BM = np.argmax(y_pred_train_ann_BM, axis=1)\n",
    "original_labels_train_ann_bm = [label_mapping_train_BM[x] for x in integer_labels_train_ann_BM]\n",
    "original_labels_train_ann_bm = pd.DataFrame(original_labels_train_ann_bm)\n",
    "original_labels_train_ann_bm['original_index'] = y_train.index\n",
    "original_labels_train_ann_bm['pred_ANN_BM'] = original_labels_train_ann_bm[0]\n",
    "original_labels_train_ann_bm = original_labels_train_ann_bm.drop(columns=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_set_ann_bmm = original_labels_train_ann_bm.merge(original_labels_test_ann_BM, on='original_index', how='outer')\n",
    "joined_set_ann_bmm['pred_ANN_BM'] = joined_set_ann_bmm['pred_ANN_BM_x'].combine_first(joined_set_ann_bmm['pred_ANN_BM_y'])\n",
    "joined_set_ann_bmm.drop(['pred_ANN_BM_x', 'pred_ANN_BM_y'], axis=1, inplace=True)\n",
    "joined_set_ann_bmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Original_frame = Original_frame.merge(joined_set_ann_bmm, on= 'original_index', how='outer')\n",
    "Original_frame"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict with best model CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the function to build the model\n",
    "\n",
    "from kerastuner import RandomSearch\n",
    "\n",
    "def build_model(hp):\n",
    "    model_cnn_bm = Sequential()\n",
    "    model_cnn_bm.add(Conv1D(hp.Int('conv1_units', min_value=32, max_value=128, step=32),  kernel_size=hp.Choice('conv1_kernel', values=[3,5]), activation='relu', input_shape=(818, 1)))\n",
    "    model_cnn_bm.add(MaxPooling1D(pool_size=hp.Choice('max_pool1', values=[2,4])))\n",
    "    model_cnn_bm.add(Dropout(hp.Float('dropout1', min_value=0.2, max_value=0.5, step=0.1)))\n",
    "    model_cnn_bm.add(Flatten())\n",
    "    model_cnn_bm.add(Dense(hp.Int('dense1_units', min_value=32, max_value=128, step=32), activation='relu'))\n",
    "    model_cnn_bm.add(Dropout(hp.Float('dropout2', min_value=0.2, max_value=0.5, step=0.1)))\n",
    "    model_cnn_bm.add(Dense(17, activation='softmax'))\n",
    "    model_cnn_bm.compile(loss='categorical_crossentropy', optimizer=Adam(hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='log')), metrics=['Recall','Precision', 'accuracy'])\n",
    "    return model_cnn_bm\n",
    "\n",
    "# define the tuner\n",
    "tuner = RandomSearch(build_model, objective='val_accuracy', max_trials=5,executions_per_trial=1,directory='tuner_results_migrated',project_name='my_cnn_tuner_join_test_to_dipl')\n",
    "\n",
    "# load your data\n",
    "# X_train, y_train, X_test, y_test = ...\n",
    "\n",
    "# train the tuner\n",
    "tuner.search(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
    "\n",
    "# get the best model\n",
    "best_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "best_model_cnn = tuner.hypermodel.build(best_hyperparameters)\n",
    "\n",
    "# evaluate the best model on the test data\n",
    "loss, recall, precision, accuracy = best_model_cnn.evaluate(X_test, y_test)\n",
    "print('Test Loss:', loss)\n",
    "print('Test Recall:', recall)\n",
    "print('Test Precision:', precision)\n",
    "print('Test Accuracy:', accuracy)\n",
    "print('Best Hyperparameters:', best_hyperparameters)\n",
    "\n",
    "best_model_cnn.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract the training and validation accuracy\n",
    "acc = best_model_cnn.history.history['accuracy']\n",
    "val_acc = best_model_cnn.history.history['val_accuracy']\n",
    "val_prec = best_model_cnn.history.history['val_precision']\n",
    "prec = best_model_cnn.history.history['precision']\n",
    "val_recall = best_model_cnn.history.history['val_recall']\n",
    "recall = best_model_cnn.history.history['recall']\n",
    "\n",
    "# Plot the accuracy\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.title('Accuracy of Best Model CNN')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "# Generate predictions on the test set\n",
    "y_bm_pred_test_cnn = best_model_cnn.predict(X_test)\n",
    "\n",
    "pred_classes = np.argmax(y_bm_pred_test_cnn, axis=1)\n",
    "true_classes = np.argmax(np.array(y_test), axis=1)\n",
    "\n",
    "\n",
    "conf_matrix = confusion_matrix(true_classes, pred_classes, labels=range(17))\n",
    "\n",
    "plt.figure(figsize =(10, 5)) \n",
    "sns.heatmap(conf_matrix, annot = True, fmt =\"d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "tensorboard_callback = TensorBoard(log_dir='./logsCNN', histogram_freq=1)\n",
    "\n",
    "best_model_cnn.fit(X_train, y_train, epochs=50, callbacks=[tensorboard_callback])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir=./logsCNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_cnn_bm_test = best_model_cnn.predict(X_test)\n",
    "label_mapping_cnn_bm = {index: label for index, label in enumerate(encoderY.get_feature_names_out())}\n",
    "integer_labels_cnn_bm = np.argmax(y_pred_cnn_bm_test, axis=1)\n",
    "original_labels_test_cnn_bm = [label_mapping_cnn_bm[x] for x in integer_labels_cnn_bm]\n",
    "original_labels_test_cnn_bm = pd.DataFrame(original_labels_test_cnn_bm)\n",
    "original_labels_test_cnn_bm['original_index'] = y_test.index\n",
    "original_labels_test_cnn_bm['pred_CNN_BM'] = original_labels_test_cnn_bm[0]\n",
    "original_labels_test_cnn_bm = original_labels_test_cnn_bm.drop(columns=0)\n",
    "#prediction on train set \n",
    "#label mapping for training predictions\n",
    "y_pred_train_cnn_bm = best_model_cnn.predict(X_train)\n",
    "label_mapping_train_cnn_bm = {index: label for index, label in enumerate(encoderY.get_feature_names_out())}\n",
    "integer_labels_train_bm_cnn = np.argmax(y_pred_train_cnn_bm, axis=1)\n",
    "original_labels_train_bm_cnn = [label_mapping_train_cnn_bm[x] for x in integer_labels_train_bm_cnn]\n",
    "original_labels_train_bm_cnn = pd.DataFrame(original_labels_train_bm_cnn)\n",
    "original_labels_train_bm_cnn['original_index'] = y_train.index\n",
    "original_labels_train_bm_cnn['pred_CNN_BM'] = original_labels_train_bm_cnn[0]\n",
    "original_labels_train_bm_cnn = original_labels_train_bm_cnn.drop(columns=0)\n",
    "joined_set_cnn_bm = original_labels_train_bm_cnn.merge(original_labels_test_cnn_bm, on='original_index', how='outer')\n",
    "joined_set_cnn_bm['pred_CNN_BM'] = joined_set_cnn_bm['pred_CNN_BM_x'].combine_first(joined_set_cnn_bm['pred_CNN_BM_y'])\n",
    "joined_set_cnn_bm.drop(['pred_CNN_BM_x', 'pred_CNN_BM_y'], axis=1, inplace=True)\n",
    "joined_set_cnn_bm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Original_frame = Original_frame.merge(joined_set_cnn_bm, on= 'original_index', how='outer')\n",
    "Original_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original_frame.to_csv('updated_results.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a2ac6d0c15653e7c58bfe1a9f33691488ddad744437e6d084867bb6ddb9db75b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
